{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils import data as data\n",
    "import pandas as pd\n",
    "from torchvision.transforms.functional import normalize\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from basicsr.data.data_util import (paired_paths_from_folder,\n",
    "                                    paired_paths_from_lmdb,\n",
    "                                    paired_paths_from_meta_info_file)\n",
    "from basicsr.data.transforms import augment, paired_random_crop\n",
    "from basicsr.utils import FileClient, imfrombytes, img2tensor, padding\n",
    "from torch.utils.data.dataloader import default_collate\n",
    "import h5py\n",
    "# local modules\n",
    "from basicsr.data.h5_augment import *\n",
    "\n",
    "from torch.utils.data import ConcatDataset\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "def transform_voxel(voxel, transpose_to_CHW=False, norm_voxel = True):\n",
    "    \"\"\"\n",
    "    Augment voxel and turn into tensor\n",
    "    @param voxel Input voxel\n",
    "    @param seed  Seed for random number generation\n",
    "    @returns Augmented voxel\n",
    "    \"\"\"\n",
    "\n",
    "    if transpose_to_CHW:\n",
    "        voxel = torch.from_numpy(voxel.transpose(2, 0, 1)).float()# H,W,C -> C,H,W\n",
    "\n",
    "    else:\n",
    "        if norm_voxel:\n",
    "            voxel = torch.from_numpy(voxel).float() / abs(max(voxel.min(), voxel.max(), key=abs))  # -1 ~ 1\n",
    "        else:\n",
    "            voxel = torch.from_numpy(voxel).float()\n",
    "\n",
    "    # if self.vox_transform:\n",
    "    #     random.seed(seed)\n",
    "    #     voxel = self.vox_transform(voxel)\n",
    "    return voxel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/deblur/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "  0%|                                                    | 0/22 [00:10<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "KL Divergence Summary (Compared to GT: Voxel):\n",
      "Refined Event KL Divergence: 4049.223441\n",
      "Event KL Divergence: 4368.650849\n",
      "Another Event KL Divergence: 4166.718810\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import h5py\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Data path\n",
    "data_path = '/workspace/data/GOPRO/train/'\n",
    "h5_folder = sorted(os.listdir(data_path))\n",
    "\n",
    "output_mother_path = '/workspace/FFTformer/results/Gopro_train/visualization'\n",
    "\n",
    "# Initialize KL divergence sums\n",
    "kl_div_refined = 0\n",
    "kl_div_event = 0\n",
    "kl_div_another_event = 0\n",
    "count = 0  # 샘플 개수 카운트\n",
    "\n",
    "# Scaling factor for Softmax conversion\n",
    "scale_factor = 5.0\n",
    "\n",
    "# Iterate through H5 files\n",
    "for h5 in tqdm(h5_folder, ncols=80):\n",
    "    imgs_path = os.path.join(data_path, h5)\n",
    "    scene = h5[:-3]\n",
    "    scene_folder = sorted(os.listdir(os.path.join(output_mother_path, scene)))\n",
    "\n",
    "    with h5py.File(imgs_path, 'r') as h5_file:\n",
    "        refined_events = h5_file['gen_event_refined']\n",
    "        voxels = h5_file['voxels']\n",
    "        events = h5_file['gen_event']\n",
    "\n",
    "        for i, event in enumerate(refined_events):\n",
    "            # Load datasets\n",
    "            refined_event = np.array(h5_file['gen_event_refined'][event])\n",
    "            voxel = np.array(h5_file['voxels']['voxel{:09d}'.format(i)])  # GT\n",
    "            event = np.array(h5_file['gen_event']['image{:09d}'.format(i)])\n",
    "            another_event = np.load(os.path.join(output_mother_path, scene, scene_folder[i], 'out.npy'))\n",
    "\n",
    "            # Convert to torch tensors\n",
    "            refined_event = torch.tensor(refined_event, dtype=torch.float32)\n",
    "            voxel = torch.tensor(voxel, dtype=torch.float32)  # GT\n",
    "            event = torch.tensor(event, dtype=torch.float32)\n",
    "            another_event = torch.tensor(another_event, dtype=torch.float32)\n",
    "\n",
    "            # Apply Softmax after scaling\n",
    "            refined_event_prob = F.softmax(refined_event * scale_factor, dim=-1) + 1e-8\n",
    "            voxel_prob = F.softmax(voxel * scale_factor, dim=-1) + 1e-8  # GT\n",
    "            event_prob = F.softmax(event * scale_factor, dim=-1) + 1e-8\n",
    "            another_event_prob = F.softmax(another_event * scale_factor, dim=-1) + 1e-8\n",
    "\n",
    "            # Compute KL Divergence\n",
    "            kl_div_refined += F.kl_div(refined_event_prob.log(), voxel_prob, reduction='batchmean').item()\n",
    "            kl_div_event += F.kl_div(event_prob.log(), voxel_prob, reduction='batchmean').item()\n",
    "            kl_div_another_event += F.kl_div(another_event_prob.log(), voxel_prob, reduction='batchmean').item()\n",
    "\n",
    "            count += 1  # 샘플 개수 카운트\n",
    "    break\n",
    "# 평균 KL Divergence 계산\n",
    "kl_div_refined /= count\n",
    "kl_div_event /= count\n",
    "kl_div_another_event /= count\n",
    "\n",
    "# Print results\n",
    "print(\"\\nKL Divergence Summary (Compared to GT: Voxel):\")\n",
    "print(f\"Refined Event KL Divergence: {kl_div_refined:.6f}\")\n",
    "print(f\"Event KL Divergence: {kl_div_event:.6f}\")\n",
    "print(f\"Another Event KL Divergence: {kl_div_another_event:.6f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3.7116e-05, 1.8242e-01, 8.1754e-01])\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "import torch\n",
    "\n",
    "# 리스트를 Tensor로 변환\n",
    "tensor_input = torch.tensor([-5,3.5,5], dtype=torch.float32)\n",
    "\n",
    "# Softmax 적용\n",
    "result = F.softmax(tensor_input, dim=-1)\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deblur",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
